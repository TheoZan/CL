{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "\n",
    "* discrete action space of size 21, 10 discharge, 10 charge, 1 noop\n",
    "* only One building\n",
    "* only one battery\n",
    "* can use custom reward with zeta parameter\n",
    "* can yous masked action space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "import citylearn\n",
    "from citylearn.energy_model import HeatPump\n",
    "from citylearn.utilities import read_json\n",
    "\n",
    "import gym\n",
    "\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from stable_baselines3 import PPO, A2C, DDPG, TD3, SAC\n",
    "\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_space_to_dict(aspace):\n",
    "    \"\"\" Only for box space \"\"\"\n",
    "    return { \"high\": aspace.high,\n",
    "             \"low\": aspace.low,\n",
    "             \"shape\": aspace.shape,\n",
    "             \"dtype\": str(aspace.dtype)\n",
    "    }\n",
    "\n",
    "def env_reset(env):\n",
    "    observations = env.reset()\n",
    "    action_space = env.action_space\n",
    "    observation_space = env.observation_space\n",
    "    building_info = env.get_building_information()\n",
    "    building_info = list(building_info)\n",
    "    action_space_dicts = [action_space_to_dict(asp) for asp in action_space]\n",
    "    observation_space_dicts = [action_space_to_dict(osp) for osp in observation_space]\n",
    "    obs_dict = {\"action_space\": action_space_dicts,\n",
    "                \"observation_space\": observation_space_dicts,\n",
    "                \"building_info\": building_info,\n",
    "                \"observation\": observations }\n",
    "    return obs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingDevices:\n",
    "  \"\"\"\n",
    "    Keeps track of all storage devices of a building.\n",
    "  \"\"\"\n",
    "  def __init__(self, building, num_building):\n",
    "    self.num_building = num_building\n",
    "    self.building = building\n",
    "    self.devices = {'battery' : Device_(building.electrical_storage, 'battery'),\n",
    "                    'cooling' : None,\n",
    "                    'dhw' : None}\n",
    "    \n",
    "  def compute_bounds(self):\n",
    "    bounds = [self.bounds_action(i) for i,j in self.devices.items() if j is not None]\n",
    "    return gym.spaces.Box(low=np.array([i[0] for i in bounds]), high=np.array([i[1] for i in bounds]), dtype=np.float64)\n",
    "  \n",
    "# ACTION 0 :  cooling\n",
    "# ACTION 1 : dhw\n",
    "# ACTION 2 : battery\n",
    "  \n",
    "  def bounds_action(self, type_action):\n",
    "    device = self.devices[type_action].device\n",
    "    if device is None:\n",
    "        return None # if return none building doest have battery\n",
    "    if type_action == 'battery':\n",
    "        capacity = device.capacity_history[-2] if len(device.capacity_history) > 1 else device.capacity\n",
    "        #HIGH\n",
    "        #get max energy that the storage unit can use to charge [kW]\n",
    "        #if trying to put more than the battery can accept reject action\n",
    "        high1 = device.get_max_input_power()/capacity\n",
    "        high2 = (device.capacity - device.soc_init)/(0.95*device.capacity) #approxim (efficiency = 0.95)\n",
    "        high = min(high1, high2, 1)\n",
    "\n",
    "        #LOW\n",
    "        low1 = -device.get_max_input_power()/capacity\n",
    "        low2 = (-device.soc_init*0.95)/device.capacity #approxim (efficiency = 0.95)\n",
    "        low = max(low1, low2, -1)\n",
    "\n",
    "    else:\n",
    "        bool_h2, bool_l2 = False, False\n",
    "        if type_action == 'cooling':\n",
    "            # print('\\ncooling')\n",
    "            space_demand = self.building.cooling_demand[self.building.time_step]\n",
    "            max_output = self.building.cooling_device.get_max_output_power(self.building.weather.outdoor_dry_bulb_temperature[self.building.time_step], False)\n",
    "            # print('space_demand',space_demand)\n",
    "            # print('max_output', max_output)\n",
    "            # print('capacity:', device.capacity)\n",
    "        else: #dhw\n",
    "            # print('\\ndhw')\n",
    "            space_demand = self.building.dhw_demand[self.building.time_step]\n",
    "            max_output = self.building.dhw_device.get_max_output_power(self.building.weather.outdoor_dry_bulb_temperature[self.building.time_step], False)\\\n",
    "            if isinstance(self.building.dhw_device, HeatPump) else self.building.dhw_device.get_max_output_power()\n",
    "            # print('space_demand',space_demand)\n",
    "            # print('max_output', max_output)\n",
    "        space_demand = 0 if space_demand is None or math.isnan(space_demand) else space_demand # case where space demand is unknown\n",
    "\n",
    "        #HIGH\n",
    "        high1 = (max_output-space_demand) / device.capacity\n",
    "        # print('high1', high1)\n",
    "        if device.max_input_power is not None:\n",
    "            bool_h2 = True\n",
    "            high2 = device.max_input_power / device.capacity\n",
    "            # print('high2', high2)\n",
    "        high3 = (device.capacity - device.soc_init) / (device.capacity*device.efficiency)\n",
    "        # print(device.capacity, device.soc_init)\n",
    "        # print('high3', high3)\n",
    "        \n",
    "        if bool_h2:\n",
    "            high = min(high1, high2, high3, 0.5)\n",
    "        else:\n",
    "            high = min(high1, high3, 0.5)\n",
    "\n",
    "\n",
    "        #LOW\n",
    "        low1 = -space_demand / device.capacity\n",
    "        # print('low1', low1)\n",
    "        if device.max_output_power is not None:\n",
    "            bool_l2 = True\n",
    "            low2 = -device.max_output_power / device.capacity\n",
    "            # print('low2',low2)\n",
    "        low3 = (-device.soc_init*device.efficiency) / device.capacity\n",
    "        # print('low3',low3)\n",
    "\n",
    "        if bool_l2:\n",
    "            low = max(low1, low2, low3, -0.5)\n",
    "        else:\n",
    "            low = max(low1, low3, -0.5)\n",
    "\n",
    "    return (low, high)\n",
    "  \n",
    "  def cost(self, zeta):\n",
    "    \"\"\"\n",
    "    Other way to compute cost.\n",
    "    1) we compute the total electrical consumption of the building,\n",
    "    2) we the offset the PV generation if existant.\n",
    "    3) we treat the case of charging and discharging the device \n",
    "    \"\"\"\n",
    "    #without dhw and cooling storage\n",
    "    #net conso = cooling + dhw + electrical_storage + nsl - solar\n",
    "    global_conso = 0\n",
    "    building = self.building\n",
    "\n",
    "    price = building.pricing.electricity_pricing[building.time_step]\n",
    "    carbon = building.carbon_intensity.carbon_intensity[building.time_step]\n",
    "\n",
    "    # print(building.time_step)\n",
    "    cooling_demand = building.energy_simulation.cooling_demand[building.time_step] + building.cooling_storage.energy_balance[building.time_step]\n",
    "    cooling_conso = building.cooling_device.get_input_power(cooling_demand, building.weather.outdoor_dry_bulb_temperature[building.time_step], heating=False)\n",
    "    global_conso += cooling_conso\n",
    "\n",
    "    dhw_demand = building.energy_simulation.dhw_demand[building.time_step] + building.dhw_storage.energy_balance[building.time_step]\n",
    "    if isinstance(building.dhw_device, HeatPump):\n",
    "            dhw_consumption = building.dhw_device.get_input_power(dhw_demand, building.weather.outdoor_dry_bulb_temperature[building.time_step], heating=True)\n",
    "    else:\n",
    "            dhw_consumption = building.dhw_device.get_input_power(dhw_demand)\n",
    "    \n",
    "    global_conso += dhw_consumption\n",
    "    global_conso += building.energy_simulation.non_shiftable_load[building.time_step]\n",
    "    global_conso -= building.pv.get_generation(building.energy_simulation.solar_generation)[building.time_step]\n",
    "\n",
    "    # print('globa_conso', global_conso)\n",
    "\n",
    "    #battery\n",
    "    #discharge \n",
    "    #energy that can be used by building (< energy actually discharged)\n",
    "    battery_conso_used = building.energy_from_electrical_storage[building.time_step]\n",
    "    #remove from global conso the energy delivered by battery (not bought from the grid)\n",
    "    # print('battery_conso_used', battery_conso_used)\n",
    "    global_conso -= battery_conso_used\n",
    "\n",
    "    #energy coming out of battery\n",
    "    soc_t = building.electrical_storage.soc[-1]\n",
    "    soc_t_1 = 0 if len(building.electrical_storage.soc) < 2 else building.electrical_storage.soc[-2]\n",
    "    battery_net_conso =  max(0, soc_t_1 - soc_t) #keep only the case where we discharge\n",
    "    # print('battery_net_conso', battery_net_conso)\n",
    "    adjusted_battery_net_conso = battery_net_conso * (1 - zeta)\n",
    "    \n",
    "    #charge\n",
    "    energy_used = building.energy_to_electrical_storage[building.time_step]\n",
    "    global_conso += (energy_used * zeta)\n",
    "    if energy_used > 0: #charging\n",
    "        #update cost of 1 unit of energy in the device\n",
    "        self.devices['battery'].update_cost(energy_used, price, carbon)\n",
    "    \n",
    "    # print('globa_conso', global_conso)\n",
    "    #can be neagtive\n",
    "    global_conso = max(0, global_conso)\n",
    "\n",
    "    # print(global_conso)\n",
    "    cost = (price + carbon) * global_conso\n",
    "    cost += self.devices['battery'].cost * adjusted_battery_net_conso\n",
    "\n",
    "    return -cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Device_:\n",
    "  def __init__(self, device, storage_type):\n",
    "    self.device = device\n",
    "    # self.price_cost = 0\n",
    "    # self.emission_cost = 0\n",
    "    self.cost = 0\n",
    "    self.storage_type = storage_type\n",
    "\n",
    "  def loss(self, cost_t, pv_offset, battery_offset):\n",
    "    \"\"\"\n",
    "    get avg price between (battery release, grid release and PV- direct consumption)\n",
    "    add relative incertainty, but true in pratice as the energy is added up in a global consumption pool \n",
    "\n",
    "    battery: if battery releases, price = avg((total released by battery - remaining conso), grid) in the case of thermal\n",
    "    in the case of battery, avg price with PV\n",
    "    \"\"\"\n",
    "    if not self.device:\n",
    "      print('not device')\n",
    "      raise ValueError\n",
    "\n",
    "    energy_used = self.device.energy_balance[-1]\n",
    "    if isinstance(energy_used, np.ndarray):\n",
    "      print('probleme energy used array instead of float')\n",
    "      energy_used = energy_used[0]\n",
    "\n",
    "    #charge\n",
    "    if energy_used > 0:\n",
    "      #if pv production, part of the energy is free\n",
    "      if pv_offset > 0:\n",
    "        energy_used = max(0, energy_used-pv_offset)\n",
    "      #if usage of battery, part of energy has been already taken into account so free\n",
    "      if battery_offset > 0:\n",
    "        energy_used = max(0, energy_used-battery_offset)\n",
    "      # self.price_cost = ((self.price_cost*self.device.soc[-2])+(energy_used*price))/self.device.soc[-1]\n",
    "      # self.emission_cost = ((self.emission_cost*self.device.soc[-2])+(energy_used*emission))/self.device.soc[-1]\n",
    "      \n",
    "      total = self.device.soc[-1]\n",
    "      if isinstance(total, np.ndarray):\n",
    "        print('probleme soc-1 array instead of float')\n",
    "        total = total[0]\n",
    "\n",
    "      prev = self.device.soc[-2]\n",
    "      if isinstance(prev, np.ndarray):\n",
    "        print('probleme soc-2 array instead of float')\n",
    "        prev = prev[0]\n",
    "\n",
    "      self.cost = ((self.cost*prev) + (energy_used*cost_t)) / total\n",
    "      return energy_used, None, None #energy_used > 0\n",
    "\n",
    "    #discharge\n",
    "    else:\n",
    "      #energy_processed is total energy used during charge/discharge process including losses\n",
    "      #energy_used is the energy_processed minus the losses (used by building)\n",
    "      energy_processed = self.device.soc[-2]-self.device.soc[-1]\n",
    "      return -energy_used, energy_processed, self.cost # -energy_used > 0, energy_processed > 0 \n",
    "\n",
    "  def update_cost(self, energy_used, price_t, emission_t):\n",
    "    prev_soc = 0 if len(self.device.soc)<2 else self.device.soc[-2]\n",
    "    cost_t = price_t + emission_t\n",
    "    self.cost = ((self.cost*prev_soc) + (energy_used*cost_t)) / self.device.soc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offset(building, mode):\n",
    "  \"\"\"\n",
    "  building is env.buildings[i]:\n",
    "  mode = 'pv' or 'battery'\n",
    "\n",
    "  each conso gets an equally distributed offset based on solar generation or battery\n",
    "  discharge\n",
    "  \"\"\"\n",
    "  if mode == 'pv':\n",
    "    if not building.solar_generation is None:\n",
    "      return 0\n",
    "    demands = [building.non_shiftable_load_demand[-2], building.electrical_storage.energy_balance[-1],\n",
    "             building.dhw_demand[-2], building.dhw_storage.energy_balance[-1],\n",
    "             building.cooling_demand[-2], building.cooling_storage.energy_balance[-1]]\n",
    "    count = len([i for i in demands if i > 0])\n",
    "    return -building.solar_generation[-2]/count\n",
    "  else:\n",
    "    if not building.solar_generation is None:\n",
    "      return 0\n",
    "    if building.electrical_storage.energy_balance[-1] >=0:\n",
    "      return 0\n",
    "    demands = [building.non_shiftable_load_demand[-2], building.dhw_demand[-2],\n",
    "            building.dhw_storage.energy_balance[-1], building.cooling_demand[-2],\n",
    "             building.cooling_storage.energy_balance[-1]]\n",
    "    count = len([i for i in demands if i > 0])\n",
    "    return -building.electrical_storage.energy_balance[-1]/count\n",
    "\n",
    "def compute_loss(building, building_devices, price, emission, outdoor_dry_bulb_temperature, zeta):\n",
    "  loss = 0\n",
    "  pv_offset = get_offset(building, 'pv') \n",
    "  battery_offset = get_offset(building, 'battery')\n",
    "  # print('pv offset',pv_offset)\n",
    "  # print('battery_offset', battery_offset)\n",
    "\n",
    "  #1) compute loss for storage devices use or update cost in storage\n",
    "  for name,device in building_devices.devices.items():\n",
    "    #if the device exists in building\n",
    "    if device:\n",
    "      energy_used, energy_processed, cost = device.loss(price*emission, pv_offset, battery_offset)\n",
    "    #else consider it exists and set energy used = 0\n",
    "    #so we can compute the remaining demand associated with the device\n",
    "    else:\n",
    "      energy_used = 0\n",
    "\n",
    "    if not energy_processed: #charge\n",
    "      #account for a part of the cost at charging time\n",
    "      loss += (price * emission) * (energy_used * zeta)\n",
    "    else: #discharge\n",
    "      loss += cost * (energy_processed * (1 - zeta))\n",
    "\n",
    "    #2) compute remaining thermal demand and add cost of remaining direct demand to answer\n",
    "    if name == 'cooling':\n",
    "      #cooling and dhw stored energy is thermal not electrical\n",
    "      remaining = building.cooling_demand[-2] - energy_used\n",
    "      # print('remaining', remaining)\n",
    "      if remaining > 0:\n",
    "        energy = max(0, building.cooling_device.get_input_power(remaining, outdoor_dry_bulb_temperature, False) - pv_offset - battery_offset)\n",
    "        # print('energy', energy)\n",
    "        loss += (price + emission) * energy\n",
    "\n",
    "    elif name == 'dhw':\n",
    "      remaining = building.dhw_demand[-2]\n",
    "      # print('remaining', remaining)\n",
    "      if remaining > 0:\n",
    "        energy = max(0, building.dhw_device.get_input_power(remaining) - pv_offset - battery_offset)\n",
    "        # print('energy', energy)\n",
    "        loss += (price + emission) * energy\n",
    "\n",
    "  #3) compute additionnal loss coming from nsl\n",
    "  nsl = max(0, building.non_shiftable_load_demand[-2] - pv_offset - battery_offset)\n",
    "  loss += (price + emission) * nsl\n",
    "  # print(loss)\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvCityGym(gym.Env):\n",
    "    \"\"\"\n",
    "    Env wrapper coming from the gym library.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, devices, discrete, custom_reward, solar, sum_cost,\n",
    "                cost_ESU, zeta, normalize, stop=None):\n",
    "        # print(schema_filepath)\n",
    "\n",
    "        self.obs = 'method_1'\n",
    "        # new obs\n",
    "        if solar:\n",
    "            self.index_keep = [0,1,2,3,22,23,27]\n",
    "            self.index_norm = [12,7,24,1,1,1,1,1]\n",
    "        else:\n",
    "            self.index_keep = [0,1,2,3,22,27]\n",
    "            # self.index_norm = [12,7,24,1,1,1,1]\n",
    "            self.index_norm = [1,1,1,1,1,1,1]\n",
    "\n",
    "        self.custom_reward = custom_reward\n",
    "        self.sum_cost = sum_cost\n",
    "        self.cost_ESU = cost_ESU\n",
    "        self.zeta = zeta\n",
    "        self.discrete = discrete\n",
    "        self.normalize = normalize\n",
    "\n",
    "        #normalization reward\n",
    "        # self.mean_std = (0.7850008976449486, 0.1339831060216876)\n",
    "\n",
    "        self.env = env\n",
    "        #list of names of devices [[]]\n",
    "        self.devices = devices\n",
    "        self.building_devices = []\n",
    "        # get the number of buildings\n",
    "        self.num_buildings = len(self.env.action_space)\n",
    "\n",
    "        low = self.env.observation_space[0].low\n",
    "        high = self.env.observation_space[0].high        \n",
    "\n",
    "        #if sum cost\n",
    "        if self.sum_cost:\n",
    "            cost_l = low[19]+low[28]\n",
    "            cost_h = high[19]+high[28]\n",
    "\n",
    "        d_low, d_high = [], []\n",
    "        for i in self.devices[0]:\n",
    "            if i == 'battery':\n",
    "                d_low.append(low[26])\n",
    "                d_high.append(high[26])\n",
    "            elif i == 'cooling':\n",
    "                d_low.append(low[24])\n",
    "                d_high.append(high[24])\n",
    "            elif i == 'dhw':\n",
    "                d_low.append(low[25])\n",
    "                d_high.append(high[25])\n",
    "\n",
    "        low = [low[i] for i in self.index_keep]\n",
    "        high = [high[i] for i in self.index_keep]\n",
    "\n",
    "        low = low + d_low\n",
    "        high = high + d_high\n",
    "\n",
    "        #if sum cost\n",
    "        if self.sum_cost:\n",
    "            low.append(cost_l)\n",
    "            high.append(cost_h)\n",
    "\n",
    "        #if cost ESU, chage if multiple buildings\n",
    "        if self.cost_ESU:\n",
    "            for i in range(len(self.devices[0])):\n",
    "                low.append(0)\n",
    "                high.append(cost_h)\n",
    "\n",
    "        if self.discrete:\n",
    "            self.action_space = gym.spaces.Discrete(21)\n",
    "            self.action_map = [-1,-0.9,-0.8,-0.7,-0.6,-0.5,-0.4,-0.3,-0.2,-0.1,0,\n",
    "                                0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "        else:\n",
    "            self.action_space = env.action_space[0]\n",
    "        \n",
    "        if self.obs == 'method_1':\n",
    "            #TODO modify for proper nb of obs\n",
    "            self.observation_space = gym.spaces.Box(low=-np.inf,\n",
    "                            high=np.inf,\n",
    "                            shape=(12,), \n",
    "                            dtype=np.float32)\n",
    "        else:\n",
    "            self.observation_space = gym.spaces.Box(low=np.array(low), high=np.array(high), dtype=np.float32)\n",
    "\n",
    "        #keep last outdoor temp for each building\n",
    "        self.temp = []\n",
    "        self.stop = stop\n",
    "        self.rewards = []\n",
    "\n",
    "        #remove if test\n",
    "        self.print_config()\n",
    "\n",
    "        # TO THINK : normalize the observation space\n",
    "\n",
    "    def reset(self):\n",
    "        obs_dict = env_reset(self.env)\n",
    "        obs = self.env.reset()\n",
    "\n",
    "        for i,e in enumerate(self.env.buildings):\n",
    "          self.building_devices.append(BuildingDevices(e,i))\n",
    "        self.temp.append(obs[i][3])\n",
    "        \n",
    "        return self.get_obs(obs)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        we apply the same action for all the buildings\n",
    "        \"\"\"\n",
    "        t = self.env.time_step\n",
    "        # print('action', action,'\\n')\n",
    "        \n",
    "        #if action is discrete convert using action mapping\n",
    "        if self.discrete:\n",
    "            action = [[self.action_conversion(action)]]\n",
    "            action = action[0]\n",
    "        # print('action', action)\n",
    "        action = [action]\n",
    "\n",
    "        # we do a step in the environment\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        # print('normal_reward', reward)\n",
    "        if t == self.stop:\n",
    "            done = True\n",
    "        \n",
    "        #custom reward 1 is the one where we can use zeta\n",
    "        if self.custom_reward == 1:\n",
    "            for i,e in enumerate(self.env.buildings):\n",
    "                rewards = []\n",
    "                rewards.append(compute_loss(e, self.building_devices[i], self.env.buildings[i].pricing.electricity_pricing[t-1],\n",
    "                self.env.buildings[i].carbon_intensity.carbon_intensity[t-1], self.temp[i], self.zeta))\n",
    "                self.temp[i] = obs[i][3]\n",
    "                #TODO multiple buildings\n",
    "                return np.array(self.get_obs(obs)), -rewards[0], done, info\n",
    "            \n",
    "        # custom reward 2 is cost without storage - cost with storage\n",
    "        elif self.custom_reward == 2:\n",
    "            for i in range(len(self.env.buildings)):\n",
    "                rewards = self.reward_diff(i)\n",
    "                # print('rewards', rewards)\n",
    "                self.rewards.append(rewards)\n",
    "                #TODO multiple buildings\n",
    "                return np.array(self.get_obs(obs)), rewards, done, info\n",
    "            \n",
    "        # custom reward 3 is the same as 1 but coded in a different way (not coded to be used w/ thermal storage)\n",
    "        elif self.custom_reward == 3:\n",
    "            rewards = []\n",
    "            for i in range(len(self.env.buildings)):\n",
    "                #TODO multiple buildings\n",
    "                rewards.append(self.building_devices[i].cost(self.zeta))\n",
    "                # print('reward3', self.building_devices[i].cost(self.zeta))\n",
    "                return np.array(self.get_obs(obs)), normalize_norm('random_discrete', 'reward', rewards[0]), done, info  \n",
    "\n",
    "        #else use normal reward \n",
    "        else:\n",
    "            #TODO multiple buildings\n",
    "            return np.array(self.get_obs(obs)), reward[0], done, info\n",
    "\n",
    "    def get_obs(self, obs):\n",
    "        #keep common obs\n",
    "        obs_ = [[o[i]/n for i,n in zip(self.index_keep, self.index_norm)] for o in obs]\n",
    "        # obs_ = list(itertools.chain(*obs_))\n",
    "\n",
    "        #add soc of each device for each building\n",
    "        for o in range(len(obs_)):\n",
    "            if 'battery' in self.devices[o]:\n",
    "                i = obs[o][26]\n",
    "                if isinstance(i, np.ndarray):\n",
    "                    print('probleme array instead of float soc battery obs')\n",
    "                    i = i[0]\n",
    "                obs_[o].append(i)\n",
    "            if 'cooling' in self.devices[o]:\n",
    "                obs_[o].append(obs[o][24])\n",
    "            if 'dhw' in self.devices[o]:\n",
    "                obs_[o].append(obs[o][25])\n",
    "\n",
    "        #add sum of costs (emission+price)\n",
    "        if self.sum_cost is True:\n",
    "            for o in range(len(obs_)):\n",
    "                #modify for buildings that dont have same nb of obs\n",
    "                obs_[o].append(obs[o][19]+obs[o][28])\n",
    "            # print(obs)\n",
    "        \n",
    "        #add cost of energy in storage device for each device of each building\n",
    "        if self.cost_ESU is True:\n",
    "            for o in range(len(obs_)):\n",
    "                for i in self.devices[o]:\n",
    "                    obs_[o].append(self.building_devices[o].devices[i].cost)\n",
    "\n",
    "        if self.normalize:\n",
    "            # print(obs_)\n",
    "            if len(obs_[0]) != 9:\n",
    "                print('/!\\ CHECK NORMALIZATION INDICES')\n",
    "            obs_ = [normalize_obs(i, 'random_discrete') for i in obs_]\n",
    "            # print(obs_)\n",
    "        return np.array(obs_)\n",
    "    \n",
    "    def action_conversion(self, action):\n",
    "        return self.action_map[action]\n",
    "    \n",
    "    def valid_action_mask(self):\n",
    "        mod_action_space = self.building_devices[0].compute_bounds()\n",
    "        act = np.array(self.action_map)\n",
    "        index = list(np.where((act>mod_action_space.low[0]) & (act<mod_action_space.high[0]))[0])\n",
    "        act = [True if i in index else False for i in range(21)]\n",
    "        act[10] = True #noop always valid\n",
    "        return act\n",
    "    \n",
    "    def print_config(self):\n",
    "        print('INIT ENV:')\n",
    "        act = 'Discrete' if self.discrete else 'Continuous'\n",
    "        print(f'ACTION SPACE: {act}')\n",
    "        print(f'Use of custom reward: {self.custom_reward}')\n",
    "        if self.custom_reward in [1,3]:\n",
    "            print(f'    zeta: {self.zeta}')\n",
    "        print('Observations kept:')\n",
    "        for i in self.index_keep:\n",
    "            print(f'    {i}: {self.env.observation_names[0][i]}')\n",
    "        for i in self.devices[0]:\n",
    "            if i == 'battery':\n",
    "                print('    26: '+self.env.observation_names[0][26])\n",
    "            elif i == 'cooling':\n",
    "                print('    24: '+self.env.observation_names[0][24])\n",
    "            elif i == 'dhw':\n",
    "                print('    25: '+self.env.observation_names[0][25])\n",
    "        if self.sum_cost or self.cost_ESU:\n",
    "            print(f'Observations ADDED:')\n",
    "            if self.sum_cost:\n",
    "                print(f'    sum_cost: {self.env.observation_names[0][19]} + {self.env.observation_names[0][28]}')\n",
    "            if self.cost_ESU:\n",
    "                print('    cost_ESU: see Device.loss')\n",
    "\n",
    "\n",
    "    def reward_diff(self, building_i):\n",
    "        r = []\n",
    "        building = self.env.buildings[building_i]\n",
    "        c1 = building.net_electricity_consumption_cost[-1]\n",
    "        c2 = building.net_electricity_consumption_emission[-1]\n",
    "        c = c1 + c2\n",
    "\n",
    "        # c1_ = building.net_electricity_consumption_without_storage_cost[-1]\n",
    "        # c2_ = building.net_electricity_consumption_without_storage_emission[-1]\n",
    "        # c_ = c1_ + c2_\n",
    "\n",
    "        c1_ = building.net_electricity_consumption_without_storage_and_pv_cost[-1]\n",
    "        c2_ = building.net_electricity_consumption_without_storage_and_pv_emission[-1]\n",
    "        c_ = c1_ + c2_\n",
    "\n",
    "        final_cost = c_ - c\n",
    "        return final_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    # Do whatever you'd like in this function to return the action mask\n",
    "    # for the current env. In this example, we assume the env has a\n",
    "    # helpful method we can rely on.\n",
    "    return env.valid_action_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_name(model_name, env, total_timesteps):\n",
    "    \"\"\"\n",
    "    get info about training session.\n",
    "    \"\"\"\n",
    "    action_space = 'Discrete' if env.discrete else 'Continuous'\n",
    "    reward = f'customR_{int(env.custom_reward)}'\n",
    "    if env.custom_reward in [1,3]:\n",
    "        reward += f'_zeta_{env.zeta}'\n",
    "    equipment = 'devices'+'-'.join([str(len(i)) for i in env.devices])\n",
    "\n",
    "    p = [model_name, str(env.num_buildings)+'building', equipment, action_space,\n",
    "        reward, 'sum_cost_'+str(int(env.sum_cost)), \n",
    "        'cost_ESU_'+str(int(env.cost_ESU)), str(total_timesteps)]\n",
    "\n",
    "    return '_'.join(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_norm(mode, cat, value):\n",
    "    \"\"\"\n",
    "    mode: random_mask\n",
    "    cat: reward\n",
    "    \"\"\"\n",
    "    if mode == 'random_discrete':\n",
    "        if cat == 'reward':\n",
    "            mean, std = -44.18679279288984, 34.31202033008597\n",
    "        elif cat == 'temp':\n",
    "            mean, std = 20.94367808219178, 7.28775091380609\n",
    "        elif cat == 'nsl':\n",
    "            mean, std = 24.83374885844749, 17.09060590705837\n",
    "        elif cat =='net_conso':\n",
    "            mean, std = 49.89326603300466, 61.492737733468275\n",
    "        elif cat == 'soc_b':\n",
    "            mean, std = 0.5886851198326962, 0.39343313608636826\n",
    "        elif cat == 'cost':\n",
    "            mean, std = 0.7850008976449486, 0.13398387077199095\n",
    "        elif cat == 'cost_esu':\n",
    "            mean, std = 0.8450902559653719, 0.12132634999196334\n",
    "            \n",
    "    return (value - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cycle(value, maxi):\n",
    "    x_norm = 2 * math.pi * value / maxi\n",
    "    return np.cos(x_norm), np.sin(x_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_obs(obs, mode):\n",
    "    normalized = []\n",
    "    for i,e in enumerate(obs):\n",
    "        if i == 0: #month\n",
    "            normalized += normalize_cycle(e, 12)\n",
    "        elif i == 1: #day type\n",
    "            normalized += normalize_cycle(e, 8)\n",
    "        elif i == 2: #hour\n",
    "            normalized += normalize_cycle(e, 24)\n",
    "        elif i == 3:\n",
    "            normalized.append(normalize_norm(mode, 'temp', e))\n",
    "        elif i == 4:\n",
    "            normalized.append(normalize_norm(mode, 'nsl', e))\n",
    "        elif i == 5:\n",
    "            normalized.append(normalize_norm(mode, 'net_conso', e))\n",
    "        elif i == 6:\n",
    "            normalized.append(normalize_norm(mode, 'soc_b', e))\n",
    "        elif i == 7:\n",
    "            normalized.append(normalize_norm(mode, 'cost', e))\n",
    "        elif i == 8:\n",
    "            normalized.append(normalize_norm(mode, 'cost_esu', e))\n",
    "        \n",
    "        else:\n",
    "            normalized.append(e)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save_model(model_name, devices, discrete, custom_reward, solar, sum_cost,\n",
    "                    cost_ESU, zeta, normalize, stop, checkpoint_path='./results', total_timesteps=None):\n",
    "\n",
    "    # first we initialize the environment (petting zoo)\n",
    "    if not total_timesteps:\n",
    "        total_timesteps = 1_500_000\n",
    "\n",
    "    if solar:\n",
    "        schema_filepath = 'schema2.json'\n",
    "    else:\n",
    "        schema_filepath = 'schema3.json'\n",
    "    schema = read_json(schema_filepath)\n",
    "    print(schema_filepath)\n",
    "    schema['root_directory'] = './'\n",
    "    env = CityLearnEnv(schema)\n",
    "    env = EnvCityGym(env, devices=devices, discrete=discrete, custom_reward=custom_reward,\n",
    "                        solar=solar, sum_cost=sum_cost, cost_ESU=cost_ESU, zeta=zeta, \n",
    "                        normalize=normalize, stop=stop)\n",
    "    if 'mask' in model_name:\n",
    "        env = ActionMasker(env, mask_fn)\n",
    "    obs = np.array(env.reset())\n",
    "\n",
    "    exp_name = get_exp_name(model_name, env,total_timesteps)\n",
    "    # load model if exist\n",
    "    if model_name == 'ppo_mask':\n",
    "        model = MaskablePPO(MaskableActorCriticPolicy, env,\n",
    "                        verbose=1, tensorboard_log='./train', device='cuda')\n",
    "    elif model_name == 'ppo':\n",
    "        model = PPO('MlpPolicy', env, verbose=0, gamma=0.99, tensorboard_log=\"./train/\", device='cuda',\n",
    "                    n_steps=10_000, learning_rate=0.0005, clip_range=0.2, ent_coef=0.001, seed=0)\n",
    "    else:\n",
    "        print('model not recognized')\n",
    "        return None\n",
    "\n",
    "    print(f'Model: {model_name}')\n",
    "    # Train the agent\n",
    "    model.learn(total_timesteps=total_timesteps, tb_log_name=exp_name,log_interval=5)\n",
    "\n",
    "    print('saving model')\n",
    "    model.save(checkpoint_path+exp_name+'.zip')\n",
    "    if 'mask' in model_name:\n",
    "        env = env.env\n",
    "    return model, env.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_heuristic(mode, discrete, custom_reward, solar, sum_cost,\n",
    "                cost_ESU, normalize, zeta=0):\n",
    "    \"\"\"\n",
    "    For 1 building.\n",
    "    mode:\n",
    "        noop: test an agent that takes no action (action 0)\n",
    "        random: test an agent that takes random action over ection space\n",
    "    \"\"\"\n",
    "    schema_filepath = 'schema2.json'\n",
    "    schema = read_json(schema_filepath)\n",
    "    schema['root_directory'] = './'\n",
    "    env = CityLearnEnv(schema)\n",
    "    env = EnvCityGym(env, devices=[['battery']], discrete=discrete, custom_reward=custom_reward,\n",
    "                solar=solar, sum_cost=sum_cost, cost_ESU=cost_ESU, normalize=normalize, zeta=zeta, stop=8760)\n",
    "\n",
    "    \n",
    "    obs = np.array(env.reset())\n",
    "    _ = env.reset()\n",
    "    done = False\n",
    "    action_list = []\n",
    "\n",
    "    while not done:\n",
    "        if mode == 'noop':\n",
    "            action = [0]\n",
    "            _, _, done, _ = env.step(action)\n",
    "        elif mode == 'random':\n",
    "            action = env.action_space[0].sample()\n",
    "            _, _, done, _ = env.step(action)\n",
    "\n",
    "        action_list.append(action[0])\n",
    "            \n",
    "    solar = env.env.buildings[0].energy_simulation.solar_generation\n",
    "    solar = env.env.buildings[0].pv.get_generation(solar)\n",
    "    conso = env.env.buildings[0].net_electricity_consumption\n",
    "    price = env.env.buildings[0].pricing.electricity_pricing\n",
    "    carbon = env.env.buildings[0].carbon_intensity.carbon_intensity\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['Time [hours]'] = [i for i in range(len(conso))]\n",
    "    df['Net conso [kWh]'] = conso\n",
    "    df['SOC [kWh]'] = env.env.buildings[0].electrical_storage.soc\n",
    "    df['Conso w/o storage [kWh]'] = env.env.buildings[0].net_electricity_consumption_without_storage\n",
    "    df['Conso w/o storage and PV [kWh]'] = env.env.buildings[0].net_electricity_consumption_without_storage_and_pv\n",
    "    df['Solar generation [kWh]'] = solar\n",
    "    # df.iloc[0][0] = 24 #first is last day of july\n",
    "    df['Cost sum(emission,price)x50'] = (price+carbon)*50\n",
    "    df['Cost price x100'] = price*100\n",
    "    df['Cost carbon x100'] = carbon*100\n",
    "\n",
    "    return df, action_list, env #all vals of df in kWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name, model_path, discrete, custom_reward, solar, sum_cost,\n",
    "                cost_ESU, normalize, zeta=0, total_timesteps=None):\n",
    "\n",
    "    # first we initialize the environment (petting zoo)\n",
    "    try:\n",
    "        if model_name == 'ppo':\n",
    "            print('PPO')\n",
    "            model = PPO.load(model_path)\n",
    "        elif model_name == 'ddpg':\n",
    "            print('DDPG')\n",
    "            model = DDPG.load(model_path)\n",
    "        elif model_name == 'a2c':\n",
    "            print('A2C')\n",
    "            model = A2C.load(model_path)\n",
    "        elif model_name == 'sac':\n",
    "            print('SAC')\n",
    "            model = SAC.load(model_path)\n",
    "        elif model_name == 'ppo_mask':\n",
    "            model = MaskablePPO.load(model_path)\n",
    "    except:\n",
    "        print('not_found')\n",
    "\n",
    "    for i in range(1):\n",
    "        done = False\n",
    "        print(f'Case {i}:', i)\n",
    "        schema_filepath = 'schema3.json'\n",
    "        schema = read_json(schema_filepath)\n",
    "        schema['root_directory'] = './'\n",
    "        env = CityLearnEnv(schema)\n",
    "        env = EnvCityGym(env, devices=[['battery']], discrete=discrete, custom_reward=custom_reward,\n",
    "                solar=solar, sum_cost=sum_cost, cost_ESU=cost_ESU, normalize=normalize, zeta=zeta, stop=8760)\n",
    "        if 'mask' in model_name:\n",
    "            env = ActionMasker(env, mask_fn)\n",
    "        print(env)\n",
    "        obs = np.array(env.reset())\n",
    "        print()\n",
    "        action_list = []\n",
    "        while not done:\n",
    "            # print(obs)\n",
    "            # obs = [i[0] if isinstance(i, np.array()) else i for i in obs]\n",
    "            # obs = np.array(obs)\n",
    "            # print(obs)\n",
    "            action, _state = model.predict(obs[0], deterministic=True)\n",
    "            # print(type(action))\n",
    "            obs, rewards, done, _ = env.step(action)\n",
    "            if isinstance(action, np.ndarray):\n",
    "                action = int(action)\n",
    "            action_list.append(action)\n",
    "\n",
    "        if discrete:\n",
    "            if 'mask' in model_name:\n",
    "                env = env.env\n",
    "            action_list = [env.action_conversion(i) for i in action_list]\n",
    "                \n",
    "            \n",
    "        # print(action_list)\n",
    "        x = pd.Series(action_list, name='action')\n",
    "        print('List of different actions taken:')\n",
    "        print(x.value_counts())\n",
    "\n",
    "        for n, nd in env.env.evaluate().groupby('name'):\n",
    "            nd = nd.pivot(index='name', columns='cost_function', values='value').round(3)\n",
    "            print(n, ':', nd.to_dict('records'))\n",
    "        print()\n",
    "\n",
    "    solar = env.env.buildings[0].energy_simulation.solar_generation\n",
    "    solar = env.env.buildings[0].pv.get_generation(solar)\n",
    "    conso = env.env.buildings[0].net_electricity_consumption\n",
    "    price = env.env.buildings[0].pricing.electricity_pricing\n",
    "    carbon = env.env.buildings[0].carbon_intensity.carbon_intensity\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # df['Time [hours]'] = [i for i in range(len(conso))]\n",
    "    df['Net conso [kWh]'] = conso\n",
    "    df['SOC [kWh]'] = env.env.buildings[0].electrical_storage.soc\n",
    "    df['Conso w/o storage [kWh]'] = env.env.buildings[0].net_electricity_consumption_without_storage\n",
    "    df['Conso w/o storage and PV [kWh]'] = env.env.buildings[0].net_electricity_consumption_without_storage_and_pv\n",
    "    df['Solar generation [kWh]'] = solar\n",
    "    # df.iloc[0][0] = 24 #first is last day of july\n",
    "    df['Cost sum(emission,price)x50'] = (price+carbon)*50\n",
    "    df['Cost price x100'] = price*100\n",
    "    df['Cost carbon x100'] = carbon*100\n",
    "\n",
    "    return df, action_list, env #all vals of df in kWh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_plot(df, y_label=None, day_mark=False, show=True, write=False):\n",
    "    \"\"\"\n",
    "    write(str): path/name.html\n",
    "    \"\"\"\n",
    "    df['Time [hours]'] = [i for i in range(len(df))]\n",
    "    fig = px.line(df, x=\"Time [hours]\", y=list(df.columns))\n",
    "    if day_mark:\n",
    "        marks = [hour for hour in df[\"Time [hours]\"] if hour%24==0]\n",
    "        for hour in marks:\n",
    "            fig.add_vline(x=hour)\n",
    "\n",
    "    if y_label:\n",
    "        fig.update_layout(yaxis_title=y_label)\n",
    "    if show:\n",
    "        fig.show()\n",
    "    if write:\n",
    "        print('writing to', write)\n",
    "        fig.write_html(write)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 1\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_filepath = 'schema3.json'\n",
    "schema = read_json(schema_filepath)\n",
    "schema['root_directory'] = './'\n",
    "\n",
    "env = CityLearnEnv(schema)\n",
    "env = EnvCityGym(env, devices=[['battery']], discrete=True, custom_reward=3,\n",
    "                    solar=False, sum_cost=True, cost_ESU=True, zeta=1, normalize=True, stop=24*30*3)\n",
    "_ = env.reset()\n",
    "len(_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = env.step(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zeta=0 is only at discharged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schema3.json\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Model: ppo_mask\n",
      "Logging to ./train\\ppo_mask_1building_devices1_Discrete_customR_3_zeta_0_sum_cost_1_cost_ESU_1_3000000_2\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | -135        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004738355 |\n",
      "|    clip_fraction        | 0.00723     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | -99.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009814117 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.89        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | -37.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101430155 |\n",
      "|    clip_fraction        | 0.0773       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.88         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 10.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 40.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008187268 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.73        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 131         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011490081 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 269          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 459          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087860245 |\n",
      "|    clip_fraction        | 0.0765       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 332          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 533          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072184913 |\n",
      "|    clip_fraction        | 0.0498       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13           |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 22.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 398         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007821085 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 16.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 461          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 692          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059558665 |\n",
      "|    clip_fraction        | 0.0638       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.68        |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.56         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    value_loss           | 8.96         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 518          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 781          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054627964 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.929       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    value_loss           | 22.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 569         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 871         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009163478 |\n",
      "|    clip_fraction        | 0.0842      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.23        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 20.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 658          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 961          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072232056 |\n",
      "|    clip_fraction        | 0.0808       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.995       |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.69         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 696          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 126          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 1054         |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049657105 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.652       |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.51         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 731         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1139        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002822023 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 762          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 125          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 1220         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021692687 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.244       |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.76         |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    value_loss           | 7.19         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 791         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1295        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003613029 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.414      |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.6         |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    value_loss           | 19.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 819          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 126          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1375         |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070049465 |\n",
      "|    clip_fraction        | 0.0717       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.635       |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.69         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 868          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 1448         |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072667883 |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.631       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.77         |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.0094      |\n",
      "|    value_loss           | 21           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 891          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1524         |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032146696 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.339       |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.04         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    value_loss           | 13.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 911          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 1611         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031131685 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.2         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2            |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 12.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 930         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1704        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001771851 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.168      |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.25        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    value_loss           | 7.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 947         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 1786        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003452982 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.343      |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.91        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 963          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 126          |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 1860         |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059064645 |\n",
      "|    clip_fraction        | 0.0579       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.00952     |\n",
      "|    value_loss           | 15.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 994          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 1934         |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041429577 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.6         |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    value_loss           | 18.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.01e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 2004         |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028019703 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.256       |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.05         |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    value_loss           | 10.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 2076        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002390158 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.169      |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.03        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.04e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 128          |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 2148         |\n",
      "|    total_timesteps      | 276480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008693896 |\n",
      "|    clip_fraction        | 0.00894      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.11        |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.32         |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    value_loss           | 9.39         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 2221         |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016813865 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.158       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.93         |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 15.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 2300         |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021220036 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.273       |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.52         |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 17.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 2377         |\n",
      "|    total_timesteps      | 307200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031956763 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.273       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.96         |\n",
      "|    n_updates            | 1490         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 18.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 2452        |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002215223 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.217      |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.36        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 14          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 2529         |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014961101 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.121       |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.54         |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    value_loss           | 9.87         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 2605        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000912007 |\n",
      "|    clip_fraction        | 0.00737     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0628     |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.57        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    value_loss           | 9.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 2681        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000756215 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0775     |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.2         |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.13e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 2759         |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024361417 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.204       |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.7          |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 16.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.15e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 2835         |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025736168 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.345       |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.37         |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -0.00745     |\n",
      "|    value_loss           | 18.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.16e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 2912         |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047361935 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.233       |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.66         |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    value_loss           | 13.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.16e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 2987         |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017975047 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.4          |\n",
      "|    n_updates            | 1890         |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 9.67         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.17e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 195           |\n",
      "|    time_elapsed         | 3066          |\n",
      "|    total_timesteps      | 399360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00068157393 |\n",
      "|    clip_fraction        | 0.00811       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0563       |\n",
      "|    explained_variance   | 0.961         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.59          |\n",
      "|    n_updates            | 1940          |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    value_loss           | 8.68          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.18e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 200           |\n",
      "|    time_elapsed         | 3142          |\n",
      "|    total_timesteps      | 409600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00055781356 |\n",
      "|    clip_fraction        | 0.00791       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0408       |\n",
      "|    explained_variance   | 0.975         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.17          |\n",
      "|    n_updates            | 1990          |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    value_loss           | 13.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 3221         |\n",
      "|    total_timesteps      | 419840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034171254 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.5          |\n",
      "|    n_updates            | 2040         |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    value_loss           | 15.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.19e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 129          |\n",
      "|    iterations           | 210          |\n",
      "|    time_elapsed         | 3309         |\n",
      "|    total_timesteps      | 430080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030435927 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.206       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.08         |\n",
      "|    n_updates            | 2090         |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    value_loss           | 19.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 215          |\n",
      "|    time_elapsed         | 3383         |\n",
      "|    total_timesteps      | 440320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037976108 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.201       |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.3          |\n",
      "|    n_updates            | 2140         |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    value_loss           | 11.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 130          |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 3457         |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017511749 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.95         |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 9.09         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.21e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 225           |\n",
      "|    time_elapsed         | 3530          |\n",
      "|    total_timesteps      | 460800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035608216 |\n",
      "|    clip_fraction        | 0.00508       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0264       |\n",
      "|    explained_variance   | 0.965         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.13          |\n",
      "|    n_updates            | 2240          |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    value_loss           | 8.37          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.22e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 230           |\n",
      "|    time_elapsed         | 3604          |\n",
      "|    total_timesteps      | 471040        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.1494765e-05 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00437      |\n",
      "|    explained_variance   | 0.961         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.31          |\n",
      "|    n_updates            | 2290          |\n",
      "|    policy_gradient_loss | -6.69e-05     |\n",
      "|    value_loss           | 15.5          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 3677        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002666853 |\n",
      "|    clip_fraction        | 0.00781     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0487     |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.11        |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    value_loss           | 15.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.23e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 240          |\n",
      "|    time_elapsed         | 3750         |\n",
      "|    total_timesteps      | 491520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006829725 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0846      |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.92         |\n",
      "|    n_updates            | 2390         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 15.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 3824        |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004267661 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.202      |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.24e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 250          |\n",
      "|    time_elapsed         | 3899         |\n",
      "|    total_timesteps      | 512000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037794465 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.201       |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.38         |\n",
      "|    n_updates            | 2490         |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    value_loss           | 7.68         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.24e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 255           |\n",
      "|    time_elapsed         | 3974          |\n",
      "|    total_timesteps      | 522240        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012524398 |\n",
      "|    clip_fraction        | 0.00166       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0122       |\n",
      "|    explained_variance   | 0.969         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.54          |\n",
      "|    n_updates            | 2540          |\n",
      "|    policy_gradient_loss | -0.000517     |\n",
      "|    value_loss           | 9.53          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.24e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 131           |\n",
      "|    iterations           | 260           |\n",
      "|    time_elapsed         | 4053          |\n",
      "|    total_timesteps      | 532480        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.8922272e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0104       |\n",
      "|    explained_variance   | 0.937         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.74          |\n",
      "|    n_updates            | 2590          |\n",
      "|    policy_gradient_loss | -0.000113     |\n",
      "|    value_loss           | 16.9          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.25e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 4111         |\n",
      "|    total_timesteps      | 542720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023953791 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.103       |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.24         |\n",
      "|    n_updates            | 2640         |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    value_loss           | 17.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 4165        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003150015 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.229      |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27        |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 16.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.26e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 133          |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 4221         |\n",
      "|    total_timesteps      | 563200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028186233 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.161       |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.02         |\n",
      "|    n_updates            | 2740         |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    value_loss           | 9.33         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 4286        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001979973 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.146      |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.07        |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    value_loss           | 5.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 4356        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010124069 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0459     |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.77        |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.26e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 134           |\n",
      "|    iterations           | 290           |\n",
      "|    time_elapsed         | 4427          |\n",
      "|    total_timesteps      | 593920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031434651 |\n",
      "|    clip_fraction        | 0.00332       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.015        |\n",
      "|    explained_variance   | 0.962         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.41          |\n",
      "|    n_updates            | 2890          |\n",
      "|    policy_gradient_loss | -0.000799     |\n",
      "|    value_loss           | 13.7          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.27e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 4492         |\n",
      "|    total_timesteps      | 604160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011243045 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0994      |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.7          |\n",
      "|    n_updates            | 2940         |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 12.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.27e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 134          |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 4556         |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020055515 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.136       |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.08         |\n",
      "|    n_updates            | 2990         |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    value_loss           | 13.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 4628        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005459779 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.184      |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.7         |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 310          |\n",
      "|    time_elapsed         | 4697         |\n",
      "|    total_timesteps      | 634880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009845805 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.035       |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.28         |\n",
      "|    n_updates            | 3090         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 5.8          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.28e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 135           |\n",
      "|    iterations           | 315           |\n",
      "|    time_elapsed         | 4768          |\n",
      "|    total_timesteps      | 645120        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4212532e-05 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00401      |\n",
      "|    explained_variance   | 0.974         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.54          |\n",
      "|    n_updates            | 3140          |\n",
      "|    policy_gradient_loss | -0.000166     |\n",
      "|    value_loss           | 11.1          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.28e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 135           |\n",
      "|    iterations           | 320           |\n",
      "|    time_elapsed         | 4838          |\n",
      "|    total_timesteps      | 655360        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4596375e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00374      |\n",
      "|    explained_variance   | 0.96          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.45          |\n",
      "|    n_updates            | 3190          |\n",
      "|    policy_gradient_loss | -8.05e-06     |\n",
      "|    value_loss           | 14.3          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 135         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 4908        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008986412 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.076      |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.78        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    value_loss           | 12.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 330          |\n",
      "|    time_elapsed         | 4977         |\n",
      "|    total_timesteps      | 675840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057722097 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.51         |\n",
      "|    n_updates            | 3290         |\n",
      "|    policy_gradient_loss | -0.0102      |\n",
      "|    value_loss           | 14.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 5050         |\n",
      "|    total_timesteps      | 686080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063534346 |\n",
      "|    clip_fraction        | 0.0615       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.336       |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.68         |\n",
      "|    n_updates            | 3340         |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    value_loss           | 7.73         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 5113        |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001378777 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0996     |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    value_loss           | 5.88        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.29e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 136          |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 5176         |\n",
      "|    total_timesteps      | 706560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004970503 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0657      |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.97         |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    value_loss           | 11.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 5244        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004741247 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.79        |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 136         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 5315        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005385197 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.88        |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 14.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 136          |\n",
      "|    iterations           | 360          |\n",
      "|    time_elapsed         | 5384         |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038336834 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.221       |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.05         |\n",
      "|    n_updates            | 3590         |\n",
      "|    policy_gradient_loss | -0.00756     |\n",
      "|    value_loss           | 13.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 5448         |\n",
      "|    total_timesteps      | 747520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037345462 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.184       |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.61         |\n",
      "|    n_updates            | 3640         |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    value_loss           | 8.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.3e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 370          |\n",
      "|    time_elapsed         | 5516         |\n",
      "|    total_timesteps      | 757760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011416345 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0595      |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.32         |\n",
      "|    n_updates            | 3690         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 5.76         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.31e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 137           |\n",
      "|    iterations           | 375           |\n",
      "|    time_elapsed         | 5583          |\n",
      "|    total_timesteps      | 768000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056085485 |\n",
      "|    clip_fraction        | 0.00654       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.071        |\n",
      "|    explained_variance   | 0.978         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 13.2          |\n",
      "|    n_updates            | 3740          |\n",
      "|    policy_gradient_loss | -0.00164      |\n",
      "|    value_loss           | 10.9          |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.76e+03   |\n",
      "|    ep_rew_mean          | 1.31e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 137        |\n",
      "|    iterations           | 380        |\n",
      "|    time_elapsed         | 5653       |\n",
      "|    total_timesteps      | 778240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00372978 |\n",
      "|    clip_fraction        | 0.0331     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.212     |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.68       |\n",
      "|    n_updates            | 3790       |\n",
      "|    policy_gradient_loss | -0.00714   |\n",
      "|    value_loss           | 13.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.31e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 137          |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 5717         |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040862905 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.248       |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.34         |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    value_loss           | 12.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.31e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 138          |\n",
      "|    iterations           | 390          |\n",
      "|    time_elapsed         | 5787         |\n",
      "|    total_timesteps      | 798720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024129495 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.112       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.59         |\n",
      "|    n_updates            | 3890         |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 11.6         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.76e+03   |\n",
      "|    ep_rew_mean          | 1.31e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 138        |\n",
      "|    iterations           | 395        |\n",
      "|    time_elapsed         | 5850       |\n",
      "|    total_timesteps      | 808960     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00252363 |\n",
      "|    clip_fraction        | 0.0242     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.146     |\n",
      "|    explained_variance   | 0.868      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.71       |\n",
      "|    n_updates            | 3940       |\n",
      "|    policy_gradient_loss | -0.00353   |\n",
      "|    value_loss           | 8.48       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.32e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 138          |\n",
      "|    iterations           | 400          |\n",
      "|    time_elapsed         | 5918         |\n",
      "|    total_timesteps      | 819200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012567218 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0378      |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.07         |\n",
      "|    n_updates            | 3990         |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 5.62         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.32e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 138           |\n",
      "|    iterations           | 405           |\n",
      "|    time_elapsed         | 5983          |\n",
      "|    total_timesteps      | 829440        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6193447e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000856     |\n",
      "|    explained_variance   | 0.977         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.15          |\n",
      "|    n_updates            | 4040          |\n",
      "|    policy_gradient_loss | -1.82e-07     |\n",
      "|    value_loss           | 9.19          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.32e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 138           |\n",
      "|    iterations           | 410           |\n",
      "|    time_elapsed         | 6053          |\n",
      "|    total_timesteps      | 839680        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7971615e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00157      |\n",
      "|    explained_variance   | 0.931         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.65          |\n",
      "|    n_updates            | 4090          |\n",
      "|    policy_gradient_loss | -1.48e-07     |\n",
      "|    value_loss           | 12.9          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 6116        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004143105 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.34        |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.32e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 138          |\n",
      "|    iterations           | 420          |\n",
      "|    time_elapsed         | 6189         |\n",
      "|    total_timesteps      | 860160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016836519 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.9          |\n",
      "|    n_updates            | 4190         |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 11.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 6257        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006605071 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0976     |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.24        |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    value_loss           | 7.29        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.33e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 139           |\n",
      "|    iterations           | 430           |\n",
      "|    time_elapsed         | 6318          |\n",
      "|    total_timesteps      | 880640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016579055 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0127       |\n",
      "|    explained_variance   | 0.961         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.68          |\n",
      "|    n_updates            | 4290          |\n",
      "|    policy_gradient_loss | -0.000124     |\n",
      "|    value_loss           | 5.53          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.34e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 435          |\n",
      "|    time_elapsed         | 6385         |\n",
      "|    total_timesteps      | 890880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014045496 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0701      |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.11         |\n",
      "|    n_updates            | 4340         |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.36e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 440          |\n",
      "|    time_elapsed         | 6455         |\n",
      "|    total_timesteps      | 901120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046347994 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.236       |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.27         |\n",
      "|    n_updates            | 4390         |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    value_loss           | 14.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.38e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 139         |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 6523        |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004587505 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    value_loss           | 14.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.39e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 450          |\n",
      "|    time_elapsed         | 6588         |\n",
      "|    total_timesteps      | 921600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037252186 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.96         |\n",
      "|    n_updates            | 4490         |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    value_loss           | 10.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.4e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 455          |\n",
      "|    time_elapsed         | 6660         |\n",
      "|    total_timesteps      | 931840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013204204 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0395      |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.48         |\n",
      "|    n_updates            | 4540         |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    value_loss           | 7.54         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.41e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 140          |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 6726         |\n",
      "|    total_timesteps      | 942080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.064329e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00457     |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83         |\n",
      "|    n_updates            | 4590         |\n",
      "|    policy_gradient_loss | 8.82e-07     |\n",
      "|    value_loss           | 6.14         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.41e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 140           |\n",
      "|    iterations           | 465           |\n",
      "|    time_elapsed         | 6796          |\n",
      "|    total_timesteps      | 952320        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7099685e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00524      |\n",
      "|    explained_variance   | 0.979         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.78          |\n",
      "|    n_updates            | 4640          |\n",
      "|    policy_gradient_loss | -5.53e-06     |\n",
      "|    value_loss           | 10.8          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 140          |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 6866         |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031587577 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.156       |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.39         |\n",
      "|    n_updates            | 4690         |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    value_loss           | 13.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 6931        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005143108 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.304      |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 140          |\n",
      "|    iterations           | 480          |\n",
      "|    time_elapsed         | 6998         |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036948354 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.133       |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.21         |\n",
      "|    n_updates            | 4790         |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    value_loss           | 8.97         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 7062        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004202913 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.134      |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.26        |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 7.34        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.44e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 140           |\n",
      "|    iterations           | 490           |\n",
      "|    time_elapsed         | 7126          |\n",
      "|    total_timesteps      | 1003520       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6449485e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.00156      |\n",
      "|    explained_variance   | 0.966         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.86          |\n",
      "|    n_updates            | 4890          |\n",
      "|    policy_gradient_loss | -1.26e-05     |\n",
      "|    value_loss           | 7.31          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 7192        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001260092 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0932     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.65        |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.76e+03   |\n",
      "|    ep_rew_mean          | 1.44e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 141        |\n",
      "|    iterations           | 500        |\n",
      "|    time_elapsed         | 7255       |\n",
      "|    total_timesteps      | 1024000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00431554 |\n",
      "|    clip_fraction        | 0.0357     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.249     |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.68       |\n",
      "|    n_updates            | 4990       |\n",
      "|    policy_gradient_loss | -0.00727   |\n",
      "|    value_loss           | 14.8       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 141          |\n",
      "|    iterations           | 505          |\n",
      "|    time_elapsed         | 7322         |\n",
      "|    total_timesteps      | 1034240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043943245 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.37        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.54         |\n",
      "|    n_updates            | 5040         |\n",
      "|    policy_gradient_loss | -0.0087      |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 141          |\n",
      "|    iterations           | 510          |\n",
      "|    time_elapsed         | 7385         |\n",
      "|    total_timesteps      | 1044480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046295226 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.261       |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.52         |\n",
      "|    n_updates            | 5090         |\n",
      "|    policy_gradient_loss | -0.00992     |\n",
      "|    value_loss           | 9.84         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 7448        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004849639 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03        |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    value_loss           | 5.62        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.45e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 141           |\n",
      "|    iterations           | 520           |\n",
      "|    time_elapsed         | 7517          |\n",
      "|    total_timesteps      | 1064960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2719178e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.000318     |\n",
      "|    explained_variance   | 0.959         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.7           |\n",
      "|    n_updates            | 5190          |\n",
      "|    policy_gradient_loss | 1.36e-07      |\n",
      "|    value_loss           | 6.73          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.45e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 141           |\n",
      "|    iterations           | 525           |\n",
      "|    time_elapsed         | 7581          |\n",
      "|    total_timesteps      | 1075200       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025399053 |\n",
      "|    clip_fraction        | 0.00166       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0114       |\n",
      "|    explained_variance   | 0.972         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.62          |\n",
      "|    n_updates            | 5240          |\n",
      "|    policy_gradient_loss | -0.000527     |\n",
      "|    value_loss           | 13.6          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 7651        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003843481 |\n",
      "|    clip_fraction        | 0.0468      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.263      |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.98        |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 141          |\n",
      "|    iterations           | 535          |\n",
      "|    time_elapsed         | 7717         |\n",
      "|    total_timesteps      | 1095680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052266214 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.299       |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.79         |\n",
      "|    n_updates            | 5340         |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 14.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 142          |\n",
      "|    iterations           | 540          |\n",
      "|    time_elapsed         | 7781         |\n",
      "|    total_timesteps      | 1105920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035466284 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.178       |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.04         |\n",
      "|    n_updates            | 5390         |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 8.36         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 142          |\n",
      "|    iterations           | 545          |\n",
      "|    time_elapsed         | 7845         |\n",
      "|    total_timesteps      | 1116160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046876958 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.154       |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.43         |\n",
      "|    n_updates            | 5440         |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    value_loss           | 6.15         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 142          |\n",
      "|    iterations           | 550          |\n",
      "|    time_elapsed         | 7907         |\n",
      "|    total_timesteps      | 1126400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006120478 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0185      |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.56         |\n",
      "|    n_updates            | 5490         |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    value_loss           | 7.85         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 142          |\n",
      "|    iterations           | 555          |\n",
      "|    time_elapsed         | 7969         |\n",
      "|    total_timesteps      | 1136640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010587085 |\n",
      "|    clip_fraction        | 0.00923      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0473      |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.22         |\n",
      "|    n_updates            | 5540         |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 13.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 142          |\n",
      "|    iterations           | 560          |\n",
      "|    time_elapsed         | 8028         |\n",
      "|    total_timesteps      | 1146880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053547206 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.3         |\n",
      "|    n_updates            | 5590         |\n",
      "|    policy_gradient_loss | -0.00883     |\n",
      "|    value_loss           | 12.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 142         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 8096        |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005153577 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.337      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.55        |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 143         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 8159        |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002052495 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.67        |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 143          |\n",
      "|    iterations           | 575          |\n",
      "|    time_elapsed         | 8220         |\n",
      "|    total_timesteps      | 1177600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032711779 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.122       |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.88         |\n",
      "|    n_updates            | 5740         |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    value_loss           | 5.93         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.45e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 143           |\n",
      "|    iterations           | 580           |\n",
      "|    time_elapsed         | 8284          |\n",
      "|    total_timesteps      | 1187840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0007246e-05 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0034       |\n",
      "|    explained_variance   | 0.969         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.73          |\n",
      "|    n_updates            | 5790          |\n",
      "|    policy_gradient_loss | -0.000101     |\n",
      "|    value_loss           | 9.46          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 8.76e+03      |\n",
      "|    ep_rew_mean          | 1.45e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 143           |\n",
      "|    iterations           | 585           |\n",
      "|    time_elapsed         | 8339          |\n",
      "|    total_timesteps      | 1198080       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047561084 |\n",
      "|    clip_fraction        | 0.00444       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0244       |\n",
      "|    explained_variance   | 0.97          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.72          |\n",
      "|    n_updates            | 5840          |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    value_loss           | 12.2          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 143          |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 8399         |\n",
      "|    total_timesteps      | 1208320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.916242e-09 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00311     |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.92         |\n",
      "|    n_updates            | 5890         |\n",
      "|    policy_gradient_loss | -8.68e-06    |\n",
      "|    value_loss           | 13.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 8458        |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004607509 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.211      |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.57        |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 14.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 144          |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 8522         |\n",
      "|    total_timesteps      | 1228800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022716494 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.102       |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.28         |\n",
      "|    n_updates            | 5990         |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    value_loss           | 7.69         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 144          |\n",
      "|    iterations           | 605          |\n",
      "|    time_elapsed         | 8583         |\n",
      "|    total_timesteps      | 1239040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010763525 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0455      |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54         |\n",
      "|    n_updates            | 6040         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    value_loss           | 5.39         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 144          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 8647         |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.028103e-06 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00683     |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.2          |\n",
      "|    n_updates            | 6090         |\n",
      "|    policy_gradient_loss | -1.91e-05    |\n",
      "|    value_loss           | 9.17         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 144          |\n",
      "|    iterations           | 615          |\n",
      "|    time_elapsed         | 8703         |\n",
      "|    total_timesteps      | 1259520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026169391 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.55         |\n",
      "|    n_updates            | 6140         |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    value_loss           | 13.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 144         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 8764        |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006747205 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.358      |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.94        |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 625         |\n",
      "|    time_elapsed         | 8822        |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005857507 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13        |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 145          |\n",
      "|    iterations           | 630          |\n",
      "|    time_elapsed         | 8879         |\n",
      "|    total_timesteps      | 1290240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066659804 |\n",
      "|    clip_fraction        | 0.0607       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.355       |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.85         |\n",
      "|    n_updates            | 6290         |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    value_loss           | 8.23         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 635         |\n",
      "|    time_elapsed         | 8942        |\n",
      "|    total_timesteps      | 1300480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002720822 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.173      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.51        |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    value_loss           | 4.52        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 145          |\n",
      "|    iterations           | 640          |\n",
      "|    time_elapsed         | 9007         |\n",
      "|    total_timesteps      | 1310720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012953973 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.084       |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.81         |\n",
      "|    n_updates            | 6390         |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 8.01         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 145         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 9065        |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004695343 |\n",
      "|    clip_fraction        | 0.0362      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.9         |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 145          |\n",
      "|    iterations           | 650          |\n",
      "|    time_elapsed         | 9120         |\n",
      "|    total_timesteps      | 1331200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062057837 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.28         |\n",
      "|    n_updates            | 6490         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 12.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 9176        |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005480121 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.358      |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3           |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 9233        |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006350193 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66        |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 6.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 146         |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 9296        |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004282686 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.35        |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    value_loss           | 4.19        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 146          |\n",
      "|    iterations           | 670          |\n",
      "|    time_elapsed         | 9354         |\n",
      "|    total_timesteps      | 1372160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020714288 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.155       |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.99         |\n",
      "|    n_updates            | 6690         |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    value_loss           | 7.86         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 146          |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 9414         |\n",
      "|    total_timesteps      | 1382400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038189318 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.26        |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.76         |\n",
      "|    n_updates            | 6740         |\n",
      "|    policy_gradient_loss | -0.00932     |\n",
      "|    value_loss           | 12.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 9472        |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006116193 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.64        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 9541        |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005195437 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.63        |\n",
      "|    n_updates            | 6840        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 147          |\n",
      "|    iterations           | 690          |\n",
      "|    time_elapsed         | 9601         |\n",
      "|    total_timesteps      | 1413120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057628746 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.26        |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.01         |\n",
      "|    n_updates            | 6890         |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 6.66         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 147          |\n",
      "|    iterations           | 695          |\n",
      "|    time_elapsed         | 9670         |\n",
      "|    total_timesteps      | 1423360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027301023 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.147       |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57         |\n",
      "|    n_updates            | 6940         |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 4.76         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 147          |\n",
      "|    iterations           | 700          |\n",
      "|    time_elapsed         | 9733         |\n",
      "|    total_timesteps      | 1433600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022866437 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.141       |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.65         |\n",
      "|    n_updates            | 6990         |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 7.48         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 147          |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 9793         |\n",
      "|    total_timesteps      | 1443840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019805536 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.173       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.37         |\n",
      "|    n_updates            | 7040         |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    value_loss           | 11.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 9857        |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005894527 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.364      |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.52        |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 9915        |\n",
      "|    total_timesteps      | 1464320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006150827 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.29       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.09        |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 13.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 9974        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006561136 |\n",
      "|    clip_fraction        | 0.0636      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.98        |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 7.33        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 147          |\n",
      "|    iterations           | 725          |\n",
      "|    time_elapsed         | 10032        |\n",
      "|    total_timesteps      | 1484800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027658697 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.183       |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91         |\n",
      "|    n_updates            | 7240         |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 4.66         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 730          |\n",
      "|    time_elapsed         | 10092        |\n",
      "|    total_timesteps      | 1495040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011377614 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0936      |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.89         |\n",
      "|    n_updates            | 7290         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 6.79         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 735          |\n",
      "|    time_elapsed         | 10156        |\n",
      "|    total_timesteps      | 1505280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052802423 |\n",
      "|    clip_fraction        | 0.0598       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.257       |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.96         |\n",
      "|    n_updates            | 7340         |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 10.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 10217        |\n",
      "|    total_timesteps      | 1515520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058090016 |\n",
      "|    clip_fraction        | 0.0626       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.7          |\n",
      "|    n_updates            | 7390         |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 12.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 745          |\n",
      "|    time_elapsed         | 10277        |\n",
      "|    total_timesteps      | 1525760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060010236 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.33        |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.12         |\n",
      "|    n_updates            | 7440         |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 10.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 10348       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004977543 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65        |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    value_loss           | 6.63        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 755          |\n",
      "|    time_elapsed         | 10407        |\n",
      "|    total_timesteps      | 1546240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034769503 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.191       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75         |\n",
      "|    n_updates            | 7540         |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    value_loss           | 4.7          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 760          |\n",
      "|    time_elapsed         | 10478        |\n",
      "|    total_timesteps      | 1556480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030170658 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.177       |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.48         |\n",
      "|    n_updates            | 7590         |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 7.4          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 148          |\n",
      "|    iterations           | 765          |\n",
      "|    time_elapsed         | 10535        |\n",
      "|    total_timesteps      | 1566720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045515075 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.268       |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.98         |\n",
      "|    n_updates            | 7640         |\n",
      "|    policy_gradient_loss | -0.00778     |\n",
      "|    value_loss           | 11.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 10594       |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004665343 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.395      |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.4         |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 10653       |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005658603 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.367      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31        |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 8.44        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 780          |\n",
      "|    time_elapsed         | 10713        |\n",
      "|    total_timesteps      | 1597440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059947427 |\n",
      "|    clip_fraction        | 0.0655       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.304       |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.65         |\n",
      "|    n_updates            | 7790         |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 5.82         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 785          |\n",
      "|    time_elapsed         | 10772        |\n",
      "|    total_timesteps      | 1607680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032857193 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 7840         |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    value_loss           | 4.91         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 790          |\n",
      "|    time_elapsed         | 10837        |\n",
      "|    total_timesteps      | 1617920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024153448 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.166       |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.12         |\n",
      "|    n_updates            | 7890         |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    value_loss           | 8.46         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 10904        |\n",
      "|    total_timesteps      | 1628160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035602476 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.256       |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.26         |\n",
      "|    n_updates            | 7940         |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    value_loss           | 11.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 10974       |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006174951 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.357      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.88        |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 805          |\n",
      "|    time_elapsed         | 11043        |\n",
      "|    total_timesteps      | 1648640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048876083 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.298       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.72         |\n",
      "|    n_updates            | 8040         |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    value_loss           | 7.48         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 810          |\n",
      "|    time_elapsed         | 11102        |\n",
      "|    total_timesteps      | 1658880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055196052 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.275       |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.31         |\n",
      "|    n_updates            | 8090         |\n",
      "|    policy_gradient_loss | -0.0089      |\n",
      "|    value_loss           | 5.84         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 11162       |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005272491 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47        |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    value_loss           | 5.33        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 820          |\n",
      "|    time_elapsed         | 11224        |\n",
      "|    total_timesteps      | 1679360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038536815 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.171       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.75         |\n",
      "|    n_updates            | 8190         |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 7.46         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 11284       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004700478 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 11340       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007931193 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.85        |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 835         |\n",
      "|    time_elapsed         | 11397       |\n",
      "|    total_timesteps      | 1710080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005892902 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97        |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 8.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 11459       |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007182746 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.314      |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67        |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 6.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 11518       |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002100092 |\n",
      "|    clip_fraction        | 0.0232      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.176      |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86        |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    value_loss           | 5.18        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 850          |\n",
      "|    time_elapsed         | 11578        |\n",
      "|    total_timesteps      | 1740800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022184926 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.165       |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08         |\n",
      "|    n_updates            | 8490         |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    value_loss           | 8.23         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 11640       |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005210738 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.274      |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7           |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 860          |\n",
      "|    time_elapsed         | 11703        |\n",
      "|    total_timesteps      | 1761280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065442137 |\n",
      "|    clip_fraction        | 0.0574       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.332       |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.06         |\n",
      "|    n_updates            | 8590         |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    value_loss           | 12.1         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 8.76e+03  |\n",
      "|    ep_rew_mean          | 1.42e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 865       |\n",
      "|    time_elapsed         | 11766     |\n",
      "|    total_timesteps      | 1771520   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0051147 |\n",
      "|    clip_fraction        | 0.0418    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.286    |\n",
      "|    explained_variance   | 0.935     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.12      |\n",
      "|    n_updates            | 8640      |\n",
      "|    policy_gradient_loss | -0.00836  |\n",
      "|    value_loss           | 8.22      |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 870          |\n",
      "|    time_elapsed         | 11830        |\n",
      "|    total_timesteps      | 1781760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070335753 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.271       |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52         |\n",
      "|    n_updates            | 8690         |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 4.27         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 875         |\n",
      "|    time_elapsed         | 11894       |\n",
      "|    total_timesteps      | 1792000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003762885 |\n",
      "|    clip_fraction        | 0.0295      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.162      |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.88        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    value_loss           | 5.55        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 880          |\n",
      "|    time_elapsed         | 11967        |\n",
      "|    total_timesteps      | 1802240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030368275 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.168       |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.83         |\n",
      "|    n_updates            | 8790         |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    value_loss           | 8.22         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 12037       |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005726992 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.305      |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.62        |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 12112       |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006257292 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.358      |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.34        |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 11          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 12185       |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005960945 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.89        |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 7.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 12259       |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005430895 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.224      |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21        |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 4.28        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 12341        |\n",
      "|    total_timesteps      | 1853440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028745076 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.16        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.73         |\n",
      "|    n_updates            | 9040         |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 6.11         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 910          |\n",
      "|    time_elapsed         | 12417        |\n",
      "|    total_timesteps      | 1863680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037320212 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.97         |\n",
      "|    n_updates            | 9090         |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    value_loss           | 7.37         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 12486        |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048862663 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.273       |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.06         |\n",
      "|    n_updates            | 9140         |\n",
      "|    policy_gradient_loss | -0.00859     |\n",
      "|    value_loss           | 10.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 12556       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005405704 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66        |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 10.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 12627       |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007352574 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.43        |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 6.43        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 930          |\n",
      "|    time_elapsed         | 12690        |\n",
      "|    total_timesteps      | 1904640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057725115 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.214       |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.55         |\n",
      "|    n_updates            | 9290         |\n",
      "|    policy_gradient_loss | -0.00977     |\n",
      "|    value_loss           | 4.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.42e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 12754        |\n",
      "|    total_timesteps      | 1914880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012401165 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0882      |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.64         |\n",
      "|    n_updates            | 9340         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 7            |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 940          |\n",
      "|    time_elapsed         | 12827        |\n",
      "|    total_timesteps      | 1925120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028060288 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.157       |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.72         |\n",
      "|    n_updates            | 9390         |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    value_loss           | 11.4         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.76e+03   |\n",
      "|    ep_rew_mean          | 1.43e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 945        |\n",
      "|    time_elapsed         | 12900      |\n",
      "|    total_timesteps      | 1935360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00473583 |\n",
      "|    clip_fraction        | 0.0487     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.305     |\n",
      "|    explained_variance   | 0.95       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.56       |\n",
      "|    n_updates            | 9440       |\n",
      "|    policy_gradient_loss | -0.00923   |\n",
      "|    value_loss           | 11.7       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 950          |\n",
      "|    time_elapsed         | 12975        |\n",
      "|    total_timesteps      | 1945600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055814357 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.324       |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.17         |\n",
      "|    n_updates            | 9490         |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 11.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 13068       |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007601764 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.34       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 9540        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 5.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 13135       |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004741989 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.198      |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    value_loss           | 3.93        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 965          |\n",
      "|    time_elapsed         | 13201        |\n",
      "|    total_timesteps      | 1976320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023016476 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.109       |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.56         |\n",
      "|    n_updates            | 9640         |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 5.95         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 970          |\n",
      "|    time_elapsed         | 13277        |\n",
      "|    total_timesteps      | 1986560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032706112 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.25         |\n",
      "|    n_updates            | 9690         |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    value_loss           | 9.89         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 975          |\n",
      "|    time_elapsed         | 13347        |\n",
      "|    total_timesteps      | 1996800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061506033 |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.305       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.03         |\n",
      "|    n_updates            | 9740         |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    value_loss           | 10.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 13420       |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007879201 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.355      |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.12        |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 13489       |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007778083 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.339      |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 4.87        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 990          |\n",
      "|    time_elapsed         | 13560        |\n",
      "|    total_timesteps      | 2027520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055858083 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.205       |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.54         |\n",
      "|    n_updates            | 9890         |\n",
      "|    policy_gradient_loss | -0.00898     |\n",
      "|    value_loss           | 3.79         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 995          |\n",
      "|    time_elapsed         | 13629        |\n",
      "|    total_timesteps      | 2037760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014999055 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0903      |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99         |\n",
      "|    n_updates            | 9940         |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 7.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1000         |\n",
      "|    time_elapsed         | 13700        |\n",
      "|    total_timesteps      | 2048000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034798095 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.191       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.61         |\n",
      "|    n_updates            | 9990         |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    value_loss           | 10.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1005         |\n",
      "|    time_elapsed         | 13776        |\n",
      "|    total_timesteps      | 2058240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049218936 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.324       |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.66         |\n",
      "|    n_updates            | 10040        |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    value_loss           | 10.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1010         |\n",
      "|    time_elapsed         | 13842        |\n",
      "|    total_timesteps      | 2068480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076444442 |\n",
      "|    clip_fraction        | 0.0738       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.6          |\n",
      "|    n_updates            | 10090        |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    value_loss           | 9.21         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 13906       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008510277 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.95        |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 4.76        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1020         |\n",
      "|    time_elapsed         | 13969        |\n",
      "|    total_timesteps      | 2088960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043646377 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.229       |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08         |\n",
      "|    n_updates            | 10190        |\n",
      "|    policy_gradient_loss | -0.00951     |\n",
      "|    value_loss           | 3.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 14042       |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002143676 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0851     |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    value_loss           | 8.5         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1030         |\n",
      "|    time_elapsed         | 14109        |\n",
      "|    total_timesteps      | 2109440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046340553 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.25         |\n",
      "|    n_updates            | 10290        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 10           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 14175       |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005576144 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.313      |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.96        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 9.96        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1040         |\n",
      "|    time_elapsed         | 14243        |\n",
      "|    total_timesteps      | 2129920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062767314 |\n",
      "|    clip_fraction        | 0.0641       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.352       |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.26         |\n",
      "|    n_updates            | 10390        |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 8.64         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1045        |\n",
      "|    time_elapsed         | 14312       |\n",
      "|    total_timesteps      | 2140160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009048643 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23        |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 4.77        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1050         |\n",
      "|    time_elapsed         | 14374        |\n",
      "|    total_timesteps      | 2150400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044656056 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.25        |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47         |\n",
      "|    n_updates            | 10490        |\n",
      "|    policy_gradient_loss | -0.00867     |\n",
      "|    value_loss           | 5.02         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1055         |\n",
      "|    time_elapsed         | 14439        |\n",
      "|    total_timesteps      | 2160640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013759523 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.1         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.5          |\n",
      "|    n_updates            | 10540        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    value_loss           | 6.41         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1060        |\n",
      "|    time_elapsed         | 14516       |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005911403 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.232      |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.49        |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 8.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1065        |\n",
      "|    time_elapsed         | 14584       |\n",
      "|    total_timesteps      | 2181120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005648122 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.377      |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.34        |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 9.57        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.76e+03   |\n",
      "|    ep_rew_mean          | 1.43e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1070       |\n",
      "|    time_elapsed         | 14647      |\n",
      "|    total_timesteps      | 2191360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00654024 |\n",
      "|    clip_fraction        | 0.0613     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.391     |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.83       |\n",
      "|    n_updates            | 10690      |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 8.44       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.76e+03   |\n",
      "|    ep_rew_mean          | 1.43e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 1075       |\n",
      "|    time_elapsed         | 14717      |\n",
      "|    total_timesteps      | 2201600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00928022 |\n",
      "|    clip_fraction        | 0.0706     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.359     |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.3        |\n",
      "|    n_updates            | 10740      |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 4.9        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1080         |\n",
      "|    time_elapsed         | 14789        |\n",
      "|    total_timesteps      | 2211840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048659607 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.256       |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.18         |\n",
      "|    n_updates            | 10790        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    value_loss           | 4.28         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 14859       |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002977319 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0962     |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.46        |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    value_loss           | 7.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 14941       |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004840806 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.245      |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.86        |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    value_loss           | 9.85        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.43e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1095         |\n",
      "|    time_elapsed         | 15019        |\n",
      "|    total_timesteps      | 2242560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070488434 |\n",
      "|    clip_fraction        | 0.0665       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.377       |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.49         |\n",
      "|    n_updates            | 10940        |\n",
      "|    policy_gradient_loss | -0.0146      |\n",
      "|    value_loss           | 8.97         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 15084       |\n",
      "|    total_timesteps      | 2252800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007492159 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.383      |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 7.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 15148       |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007820706 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.312      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 4.42        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1110         |\n",
      "|    time_elapsed         | 15218        |\n",
      "|    total_timesteps      | 2273280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038179636 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.252       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.46         |\n",
      "|    n_updates            | 11090        |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    value_loss           | 4.62         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1115         |\n",
      "|    time_elapsed         | 15291        |\n",
      "|    total_timesteps      | 2283520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022141726 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.125       |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.49         |\n",
      "|    n_updates            | 11140        |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    value_loss           | 7.04         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 15360       |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004480027 |\n",
      "|    clip_fraction        | 0.0473      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.38        |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 9.41        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1125         |\n",
      "|    time_elapsed         | 15441        |\n",
      "|    total_timesteps      | 2304000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056582373 |\n",
      "|    clip_fraction        | 0.0565       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.35         |\n",
      "|    n_updates            | 11240        |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 10.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1130         |\n",
      "|    time_elapsed         | 15508        |\n",
      "|    total_timesteps      | 2314240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066935397 |\n",
      "|    clip_fraction        | 0.0674       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.13         |\n",
      "|    n_updates            | 11290        |\n",
      "|    policy_gradient_loss | -0.0133      |\n",
      "|    value_loss           | 8.14         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 15589       |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008069538 |\n",
      "|    clip_fraction        | 0.0714      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.3        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 5.54        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1140         |\n",
      "|    time_elapsed         | 15662        |\n",
      "|    total_timesteps      | 2334720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042431476 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.242       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36         |\n",
      "|    n_updates            | 11390        |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    value_loss           | 4.71         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1145         |\n",
      "|    time_elapsed         | 15732        |\n",
      "|    total_timesteps      | 2344960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029871073 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.151       |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.11         |\n",
      "|    n_updates            | 11440        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 8.13         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 15797       |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006115104 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86        |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 9.51        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1155         |\n",
      "|    time_elapsed         | 15861        |\n",
      "|    total_timesteps      | 2365440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066187354 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.352       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.93         |\n",
      "|    n_updates            | 11540        |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 9.23         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 15926       |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007622117 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.49        |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 7.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 15992       |\n",
      "|    total_timesteps      | 2385920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008747609 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2         |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 4.24        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1170         |\n",
      "|    time_elapsed         | 16063        |\n",
      "|    total_timesteps      | 2396160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035343864 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.6          |\n",
      "|    n_updates            | 11690        |\n",
      "|    policy_gradient_loss | -0.00725     |\n",
      "|    value_loss           | 5.31         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1175         |\n",
      "|    time_elapsed         | 16142        |\n",
      "|    total_timesteps      | 2406400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037362024 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.151       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.62         |\n",
      "|    n_updates            | 11740        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    value_loss           | 6.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1180         |\n",
      "|    time_elapsed         | 16211        |\n",
      "|    total_timesteps      | 2416640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068243053 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.288       |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.61         |\n",
      "|    n_updates            | 11790        |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    value_loss           | 10.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1185         |\n",
      "|    time_elapsed         | 16281        |\n",
      "|    total_timesteps      | 2426880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055910274 |\n",
      "|    clip_fraction        | 0.0578       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.354       |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.5          |\n",
      "|    n_updates            | 11840        |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 10.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1190         |\n",
      "|    time_elapsed         | 16345        |\n",
      "|    total_timesteps      | 2437120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069987387 |\n",
      "|    clip_fraction        | 0.0644       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.347       |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 11890        |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 6.02         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1195         |\n",
      "|    time_elapsed         | 16409        |\n",
      "|    total_timesteps      | 2447360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068787746 |\n",
      "|    clip_fraction        | 0.0637       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.274       |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17         |\n",
      "|    n_updates            | 11940        |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1200         |\n",
      "|    time_elapsed         | 16473        |\n",
      "|    total_timesteps      | 2457600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041680215 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.119       |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05         |\n",
      "|    n_updates            | 11990        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 4.85         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | 1.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 16543       |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004148109 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.171      |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.72        |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    value_loss           | 8.01        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1210         |\n",
      "|    time_elapsed         | 16615        |\n",
      "|    total_timesteps      | 2478080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052498407 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.283       |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.57         |\n",
      "|    n_updates            | 12090        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    value_loss           | 10.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | 1.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 1215         |\n",
      "|    time_elapsed         | 16691        |\n",
      "|    total_timesteps      | 2488320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066238986 |\n",
      "|    clip_fraction        | 0.064        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.36        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.41         |\n",
      "|    n_updates            | 12140        |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    value_loss           | 10.3         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "m = train_save_model(model_name='ppo_mask', devices=[['battery']], discrete=True,\n",
    "                    custom_reward=3, solar=False, sum_cost=True, cost_ESU=True, zeta=0,\n",
    "                    normalize=True, stop=None, checkpoint_path='./weights/', total_timesteps=3_000_000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise training curves in Tensorboard use: CTRL + MAJ + P, Python: Launch Tensorboard, select folder ./train (VSCODE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Single model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints:\n",
    "  * name of model\n",
    "  * config of the env\n",
    "  * list and number of different actions taken by env\n",
    "  * list of metrics w/ associated cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = 'weights_r3\\ppo_mask_1building_devices1_Discrete_customR_3_zeta_0_sum_cost_1_cost_ESU_1_3000000.zip'\n",
    "n_steps=10_000, learning_rate=0.0005, clip_range=0.2, ent_coef=0.001, timesteps=3e6\n",
    "\n",
    "List of different actions taken:\n",
    " 0.2    7935\n",
    " 0.3     659\n",
    "-0.1     165\n",
    "Name: action, dtype: int64\n",
    "Building_1 : [{'carbon_emissions': 1.002, 'cost': 1.004, 'electricity_consumption': 1.001, 'zero_net_energy': 1.001}]\n",
    "District : [{'1 - load_factor': 1.01, 'average_daily_peak': 1.016, 'carbon_emissions': 1.002, 'cost': 1.004, 'electricity_consumption': 1.001, 'peak_demand': 1.0, 'ramping': 1.028, 'zero_net_energy': 1.001}]\n",
    "\n",
    "'weights\\ppo_mask_1building_devices1_Discrete_customR_3_zeta_0_sum_cost_1_cost_ESU_1_2500000.zip'\n",
    "n_steps=10_000, learning_rate=0.0003, clip_range=0.2, ent_coef=0.001, timesteps=2.5e6\n",
    "List of different actions taken:\n",
    "0.0    7634\n",
    "0.5    1125\n",
    "Name: action, dtype: int64\n",
    "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.001, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
    "District : [{'1 - load_factor': 1.016, 'average_daily_peak': 1.002, 'carbon_emissions': 1.0, 'cost': 1.001, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.002, 'zero_net_energy': 1.0}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      " 0.0    5771\n",
      " 0.1    1178\n",
      "-0.1     875\n",
      " 0.2     868\n",
      "-0.3      32\n",
      " 0.4      26\n",
      " 0.5       9\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.007, 'cost': 0.979, 'electricity_consumption': 1.007, 'zero_net_energy': 1.006}]\n",
      "District : [{'1 - load_factor': 1.035, 'average_daily_peak': 1.075, 'carbon_emissions': 1.007, 'cost': 0.979, 'electricity_consumption': 1.007, 'peak_demand': 1.082, 'ramping': 1.165, 'zero_net_energy': 1.006}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# path = 'weights_r3\\ppo_mask_1building_devices1_Discrete_customR_3_zeta_0_sum_cost_1_cost_ESU_1_3000000.zip'\n",
    "path = 'weights\\ppo_mask_1building_devices1_Discrete_customR_3_zeta_0_sum_cost_1_cost_ESU_1_3000000.zip'\n",
    "\n",
    "df, actions, env = test_model('ppo_mask', model_path=path, discrete=True, custom_reward=3, sum_cost=True,\n",
    "                solar=False, cost_ESU=True, normalize=True, zeta=1, total_timesteps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test min max normalization for soc, net, nsl (we know the maximum bound before hand, keeps between 0-1 which is coherent\n",
    "# (battery soc already between 0-1)) and keep norm for other                       #5\n",
    "\n",
    "\n",
    "# use future values to see impact of delays on the result                           #last -1\n",
    "\n",
    "#re test different values of alpha when using obs normalization                     #4\n",
    "\n",
    "#augmenter le poid du carbon dans le cout                                           #last -2\n",
    "\n",
    "#test more baselines 1) noop 2) random 3) same algo no modifications (base ppo)     #1\n",
    "\n",
    "#episodic analysis of resulting policy, add to paper                                #2\n",
    "\n",
    "#test reward scaling or normalization (last)                                        #3\n",
    "\n",
    "#add a section in experiment \n",
    "# 2 scenario: 1battery, 1battery w/solar                                            #same as 2\n",
    "#analysis of behavior, yearly and zoom in, explain part where no or little decisions are taken \n",
    "\n",
    "#test solutions w/hyperparameter tuning                                             #last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9859999999999998"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.007+0.979"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results of single test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to test_normalize.html\n"
     ]
    }
   ],
   "source": [
    "fig_plot(df, day_mark=False, show=False, write='test_normalize2.html')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run batch of models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints:\n",
    "  * name of model\n",
    "  * config of the env\n",
    "  * list and number of different actions taken by env\n",
    "  * list of metrics w/ associated costA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.01_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.02_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.03_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0.0    8742\n",
      "0.1      17\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.001, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.001, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.04_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.05_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0.0    8509\n",
      "0.1     250\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.1_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.2_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.3_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.4_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      " 0.0    8758\n",
      "-0.1       1\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.5_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "-0.1    7340\n",
      " 0.0    1419\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.6_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "-0.1    8757\n",
      " 0.0       2\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.7_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.8_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0.9_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_0_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "0    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n",
      "ppo_mask_1building_devices1_Discrete_customR_3_zeta_1_sum_cost_1_cost_ESU_1_3000000.zip\n",
      "Case 0: 0\n",
      "INIT ENV:\n",
      "ACTION SPACE: Discrete\n",
      "Use of custom reward: 3\n",
      "    zeta: 0\n",
      "Observations kept:\n",
      "    0: month\n",
      "    1: day_type\n",
      "    2: hour\n",
      "    3: outdoor_dry_bulb_temperature\n",
      "    22: non_shiftable_load\n",
      "    27: net_electricity_consumption\n",
      "    26: electrical_storage_soc\n",
      "Observations ADDED:\n",
      "    sum_cost: carbon_intensity + electricity_pricing\n",
      "    cost_ESU: see Device.loss\n",
      "<ActionMasker<EnvCityGym instance>>\n",
      "\n",
      "List of different actions taken:\n",
      "-0.1    8759\n",
      "Name: action, dtype: int64\n",
      "Building_1 : [{'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'zero_net_energy': 1.0}]\n",
      "District : [{'1 - load_factor': 1.0, 'average_daily_peak': 1.0, 'carbon_emissions': 1.0, 'cost': 1.0, 'electricity_consumption': 1.0, 'peak_demand': 1.0, 'ramping': 1.0, 'zero_net_energy': 1.0}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights_folder = './weights_r3.1/'\n",
    "\n",
    "for i in os.listdir(weights_folder):\n",
    "    print(i)\n",
    "    if 'mask' in i:\n",
    "        model_name = 'ppo_mask'\n",
    "\n",
    "        df, actions, env = test_model(model_name, model_path=weights_folder+i, discrete=True, custom_reward=3, sum_cost=True,\n",
    "                    cost_ESU=True, solar=False, zeta=0, total_timesteps=None)\n",
    "        \n",
    "        #print fig here\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_solar(env):\n",
    "    df_solar = pd.DataFrame()\n",
    "    for i,b in enumerate(env.buildings):\n",
    "        solar = b.energy_simulation.solar_generation\n",
    "        solar = b.pv.get_generation(solar)\n",
    "        df_solar['building_'+str(i)] = solar\n",
    "    return df_solar\n",
    "\n",
    "def data_nsl(env):\n",
    "    df = pd.DataFrame()\n",
    "    for i,b in enumerate(env.buildings):\n",
    "        x = b.energy_simulation.non_shiftable_load\n",
    "        df['building_'+str(i)] = x\n",
    "    return df\n",
    "\n",
    "def data_cool(env):\n",
    "    df = pd.DataFrame()\n",
    "    for i,b in enumerate(env.buildings):\n",
    "        x = b.energy_simulation.cooling_demand\n",
    "        df['building_'+str(i)] = x\n",
    "    return df\n",
    "\n",
    "def data_dhw(env):\n",
    "    df = pd.DataFrame()\n",
    "    for i,b in enumerate(env.buildings):\n",
    "        x = b.energy_simulation.dhw_demand\n",
    "        df['building_'+str(i)] = x\n",
    "    return df\n",
    "\n",
    "def data_cost(env):\n",
    "    #cost is same for each b\n",
    "    df_cost = pd.DataFrame()\n",
    "    price = env.buildings[0].pricing.electricity_pricing\n",
    "    # price = pd.read_csv('./pricing.csv')['Electricity Pricing [$]']*100\n",
    "    carbon = env.buildings[0].carbon_intensity.carbon_intensity\n",
    "\n",
    "    df_cost['Cost sum(emission,price)x50'] = (price+carbon)*50\n",
    "    df_cost['Cost price x100'] = price*100\n",
    "    df_cost['Cost carbon x100'] = carbon*100\n",
    "\n",
    "    return df_cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at replay buffer actions during training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
